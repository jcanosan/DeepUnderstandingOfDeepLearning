{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U3TmybM4yMw"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# for DL modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for number-crunching\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# for dataset management\n",
    "import pandas as pd\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2anVFzBXGdwH"
   },
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ohXIxzt4_U2"
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "data = data[data['total sulfur dioxide'] < 200]  # drop a few outliers\n",
    "\n",
    "# z-score all columns except for quality\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop('quality')\n",
    "data[cols2zscore] = data[cols2zscore].apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize good and bad wines according to certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binarized_column_boolean_quality(data, quality_threshold):\n",
    "    data['boolQuality'] = 0\n",
    "    bool_quality = (data['quality'] > quality_threshold).astype(int)\n",
    "    data['boolQuality'] = bool_quality\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGQd7xmM5Gns"
   },
   "source": [
    "# Re-organize the data: train/test in DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(data):\n",
    "    # convert from pandas dataframe to tensor\n",
    "    dataT = torch.tensor(data[cols2zscore].values).float()\n",
    "    labels = torch.tensor(data['boolQuality'].values).float()\n",
    "    labels = labels[:, None]  # transform to matrix\n",
    "\n",
    "    # use scikitlearn to split the data\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        dataT, labels, test_size=.1)\n",
    "\n",
    "    # then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "    train_data = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "    test_data = torch.utils.data.TensorDataset(test_data, test_labels)\n",
    "\n",
    "    # finally, translate into dataloader objects\n",
    "    batchsize = 8\n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=batchsize,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "    test_loader = DataLoader(test_data,\n",
    "                             batch_size=test_data.tensors[0].shape[0])\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7g0mivk5GqP"
   },
   "source": [
    "# Now for the DL part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0vAnQi9DNRa"
   },
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "class ANNwine(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ### input layer\n",
    "        self.input = nn.Linear(11, 16)\n",
    "\n",
    "        ### hidden layers\n",
    "        self.fc1 = nn.Linear(16, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "\n",
    "        ### output layer\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        # get activation function type\n",
    "        # this code replaces torch.relu with torch.<self.actfun>\n",
    "        actfun = getattr(torch.nn, 'LeakyReLU')\n",
    "        x = actfun()(self.input(x))\n",
    "        x = actfun()(self.fc1(x))\n",
    "        x = actfun()(self.fc2(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qtOQaNul-7q"
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "net = ANNwine()\n",
    "net(torch.randn(10, 11)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuCixgNfDMZS"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XRPe56rGp2k"
   },
   "outputs": [],
   "source": [
    "# global parameter\n",
    "numepochs = 500\n",
    "\n",
    "\n",
    "def trainTheModel(winenet, train_loader, test_loader):\n",
    "    # loss function and optimizer\n",
    "    lossfun = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=.001)\n",
    "\n",
    "    # initialize losses\n",
    "    losses = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epochi in range(numepochs):\n",
    "\n",
    "        # turn on training mode\n",
    "        winenet.train()\n",
    "\n",
    "        # loop over training data batches\n",
    "        batchAcc = []\n",
    "        batchLoss = []\n",
    "        for X, y in train_loader:\n",
    "\n",
    "            # forward pass and loss\n",
    "            yHat = winenet(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # compute training accuracy for this batch\n",
    "            batchAcc.append(100 * torch.mean(((yHat > 0) == y).float()).item())\n",
    "        # end of batch loop...\n",
    "\n",
    "        # now that we've trained through the batches, get their average training accuracy\n",
    "        trainAcc.append(np.mean(batchAcc))\n",
    "\n",
    "        # and get average losses across the batches\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "        # test accuracy\n",
    "        winenet.eval()\n",
    "        X, y = next(iter(test_loader))  # extract X,y from test dataloader\n",
    "        with torch.no_grad():  # deactivates autograd\n",
    "            yHat = winenet(X)\n",
    "        testAcc.append(100 * torch.mean(((yHat > 0) == y).float()).item())\n",
    "\n",
    "    # function output\n",
    "    return trainAcc, testAcc, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL7EqhYjGp51"
   },
   "outputs": [],
   "source": [
    "quality_thresholds = [4.5, 5.5, 6.5]\n",
    "\n",
    "train_acc_by_activation = {}\n",
    "test_acc_by_activation = {}\n",
    "losses = {}\n",
    "per_quality_accuracy = {}\n",
    "\n",
    "for i, threshold in enumerate(quality_thresholds):\n",
    "    data_for_threshold = create_binarized_column_boolean_quality(\n",
    "        deepcopy(data), threshold)\n",
    "    train_loader, test_loader = create_dataloaders(data_for_threshold)\n",
    "\n",
    "    # create a model and train it\n",
    "    winenet = ANNwine()\n",
    "    train_acc_by_activation[threshold], test_acc_by_activation[\n",
    "        threshold], losses[threshold] = trainTheModel(winenet, train_loader,\n",
    "                                                      test_loader)\n",
    "\n",
    "    # compute accuracy per quality type\n",
    "    X, y = next(iter(test_loader))\n",
    "    itemAccuracy = ((winenet(X) > 0) == y).float()\n",
    "    per_quality_accuracy[threshold] = [\n",
    "        100 * torch.mean(itemAccuracy[y == 0]),\n",
    "        100 * torch.mean(itemAccuracy[y == 1])\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7mAB4utDMeh"
   },
   "outputs": [],
   "source": [
    "# plot some results\n",
    "fig, ax = plt.subplots(3, 3, figsize=(20, 16))\n",
    "\n",
    "# common features\n",
    "for i, threshold in enumerate(quality_thresholds):\n",
    "    ax[i][0].plot(losses[threshold])\n",
    "    ax[i][0].set_title('Losses')\n",
    "    ax[i][1].legend([\"Train\", \"Test\"])\n",
    "    ax[i][0].set_xlabel('Epoch')\n",
    "    ax[i][0].set_ylabel('Accuracy (%)')\n",
    "    ax[i][0].grid()\n",
    "\n",
    "    ax[i][1].plot(train_acc_by_activation[threshold])\n",
    "    ax[i][1].plot(test_acc_by_activation[threshold])\n",
    "    ax[i][1].set_title('Accuracy')\n",
    "    ax[i][1].legend([\"Train\", \"Test\"])\n",
    "    ax[i][1].set_xlabel('Epoch')\n",
    "    ax[i][1].set_ylabel('Accuracy (%)')\n",
    "    ax[i][1].set_ylim([0, 100])\n",
    "    ax[i][1].grid()\n",
    "\n",
    "    # plot the per-quality accuracy\n",
    "    bh = ax[i, 2].bar(['Bad', 'Good'], per_quality_accuracy[threshold])\n",
    "    ax[i, 2].set_ylim([0, 100])\n",
    "    ax[i, 2].set_xlabel('Wine quality')\n",
    "    ax[i, 2].set_ylabel('Test accuracy')\n",
    "    ax[i, 2].set_title('Per-qual acc. with qualthresh ' + str(threshold + .5))\n",
    "\n",
    "    # print the counts on top of each bar\n",
    "    for i, r in enumerate(bh):\n",
    "        N = torch.sum(train_loader.dataset.tensors[1] == i).item()\n",
    "        ax[i, 2].text(r.get_x() + r.get_width() / 2,\n",
    "                      r.get_height() + 1,\n",
    "                      'N=%s' % N,\n",
    "                      ha='center',\n",
    "                      va='bottom',\n",
    "                      fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKg1vIUcdZGvMDyHXEbLxS",
   "collapsed_sections": [],
   "name": "DUDL_metaparams_ActivationComparisons.ipynb",
   "provenance": [
    {
     "file_id": "1ZD_ADbh6qrlHE16V7Yc8VF9Vrn2c6bMQ",
     "timestamp": 1617047906157
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
