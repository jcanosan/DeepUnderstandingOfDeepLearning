{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "nPerClust = 100\n",
    "blur = 1\n",
    "\n",
    "A = [1, 1]\n",
    "B = [5, 1]\n",
    "C = [1, 5]\n",
    "\n",
    "# generate data\n",
    "a = [A[0]+np.random.randn(nPerClust)*blur, A[1]+np.random.randn(nPerClust)*blur]\n",
    "b = [B[0]+np.random.randn(nPerClust)*blur, B[1]+np.random.randn(nPerClust)*blur]\n",
    "c = [C[0]+np.random.randn(nPerClust)*blur, C[1]+np.random.randn(nPerClust)*blur]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.vstack((np.zeros((nPerClust, 1)), np.ones((nPerClust, 1)), 1 + np.ones((nPerClust, 1))))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a, b, c)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.squeeze(torch.tensor(labels_np).long())\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0], data[np.where(labels==0)[0],1], 'bs')\n",
    "plt.plot(data[np.where(labels==1)[0],0], data[np.where(labels==1)[0],1], 'ko')\n",
    "plt.plot(data[np.where(labels==2)[0],0], data[np.where(labels==2)[0],1], 'r^')\n",
    "plt.title('The qwerties!')\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "ANN = nn.Sequential(\n",
    "    nn.Linear(2, 4),   # input layer\n",
    "    nn.ReLU(),         # activation\n",
    "    nn.Linear(4, 3),   # output layer\n",
    ")\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANN.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numepochs = 10000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "  # forward pass\n",
    "  yHat = ANN(data)\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat, labels)\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # compute accuracy\n",
    "  matches = torch.argmax(yHat, axis=1) == labels # booleans (false/true)\n",
    "  matchesNumeric = matches.float()              # convert to numbers (0/1)\n",
    "  accuracyPct = 100*torch.mean(matchesNumeric)  # average and x100 \n",
    "  ongoingAcc.append( accuracyPct )              # add to list of accuracies\n",
    "\n",
    "# final forward pass\n",
    "predictions = ANN(data)\n",
    "  \n",
    "predlabels = torch.argmax(predictions,axis=1)\n",
    "totalacc = 100*torch.mean((predlabels == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracy\n",
    "print('Final accuracy: %g%%' %totalacc)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(13,4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(ongoingAcc)\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "plt.show()\n",
    "# run training again to see whether this performance is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all model predictions sum to 1, but only when converted to softmax\n",
    "sm = nn.Softmax(1)\n",
    "torch.sum(sm(yHat),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw model outputs\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "colourshape = [\"bs\", \"ko\", \"r^\"]\n",
    "for i in range (3):\n",
    "    plt.plot(yHat[:,i].detach(), colourshape[i], markerfacecolor='w')\n",
    "\n",
    "plt.xlabel('Stimulus number')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend(['setosa','versicolor','virginica'])\n",
    "plt.show()\n",
    "\n",
    "# try it again without the softmax!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
