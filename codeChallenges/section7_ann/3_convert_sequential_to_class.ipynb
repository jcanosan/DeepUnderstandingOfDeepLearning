{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7-LiwqUMGYL"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-SP8NPsMNRL"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "nPerClust = 100\n",
    "blur = 1\n",
    "\n",
    "A = [  1,  3 ]\n",
    "B = [  1, -2 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*blur , A[1]+np.random.randn(nPerClust)*blur ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*blur , B[1]+np.random.randn(nPerClust)*blur ]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.vstack((np.zeros((nPerClust,1)),np.ones((nPerClust,1))))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a,b)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'bs')\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'ko')\n",
    "plt.title('The qwerties!')\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Oi0wAb5ze3Q"
   },
   "source": [
    "# Classes to build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krQeh5wYMNla"
   },
   "outputs": [],
   "source": [
    "class ANNMultilayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # model architecture\n",
    "        self._input = nn.Linear(2,16)  # input layer\n",
    "        self._hidden = nn.Linear(16,1)  # hidden layer\n",
    "        self._output = nn.Linear(1,1)  # output unit\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self._input(input))\n",
    "        x = F.relu(self._hidden(x))\n",
    "        x = self._output(x)\n",
    "        ann_result = torch.sigmoid(x)  # final activation unit\n",
    "        return ann_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNPipeline():\n",
    "    def __init__(self, learning_rate):\n",
    "        self._ann = ANNMultilayer()\n",
    "        # loss function\n",
    "        self._lossfun = nn.BCELoss() # but better to use BCEWithLogitsLoss\n",
    "        # optimizer\n",
    "        self._optimizer = torch.optim.SGD(self._ann.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train(self, numepochs=1000):\n",
    "        # initialize losses\n",
    "        losses = torch.zeros(numepochs)\n",
    "        # loop over epochs\n",
    "        for epochi in range(numepochs):\n",
    "            # forward pass\n",
    "            yHat = self._ann.forward(data)\n",
    "            # compute loss\n",
    "            loss = self._lossfun(yHat,labels)\n",
    "            losses[epochi] = loss\n",
    "            # backprop\n",
    "            self._optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "        # final forward pass\n",
    "        predictions = self._ann.forward(data)\n",
    "        # compute the predictions and report accuracy\n",
    "        # NOTE: Wasn't this \">0\" previously?!?!\n",
    "        totalacc = 100*torch.mean(((predictions > .5) == labels).float())\n",
    "        return losses, predictions, totalacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd3rIbQUzkKv"
   },
   "source": [
    "# Test the new code by running it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SatsWGs3x6Kg"
   },
   "outputs": [],
   "source": [
    "numepochs = 1000\n",
    "# create everything\n",
    "net = ANNPipeline(.01)\n",
    "# run it\n",
    "losses, predictions, totalacc = net.train(numepochs)\n",
    "# report accuracy\n",
    "print(f'Final accuracy: {totalacc}')\n",
    "\n",
    "# show the losses\n",
    "plt.plot(losses.detach(),'o',markerfacecolor='w',linewidth=.1)\n",
    "plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqvlfINnzojn"
   },
   "source": [
    "# Now for the real test (varying learning rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1TCt0mpMNxC"
   },
   "outputs": [],
   "source": [
    "# learning rates\n",
    "learning_rates = np.linspace(.001,.1,50)\n",
    "# initialize\n",
    "accByLR = []\n",
    "allLosses = np.zeros((len(learning_rates), numepochs))\n",
    "\n",
    "# the loop\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    # create and run the model\n",
    "    net = ANNPipeline(lr)\n",
    "    losses, predictions, totalacc = net.train(numepochs)\n",
    "    # store the results\n",
    "    accByLR.append(totalacc)\n",
    "    allLosses[i,:] = losses.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpSpm3klet-"
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,4))\n",
    "\n",
    "ax[0].plot(learning_rates,accByLR,'s-')\n",
    "ax[0].set_xlabel('Learning rate')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('Accuracy by learning rate')\n",
    "\n",
    "ax[1].plot(allLosses.T)\n",
    "ax[1].set_title('Losses by learning rate')\n",
    "ax[1].set_xlabel('Epoch number')\n",
    "ax[1].set_ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QSbPkVrWWDO"
   },
   "outputs": [],
   "source": [
    "accByLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_lVYxTsi871"
   },
   "outputs": [],
   "source": [
    "sum(torch.tensor(accByLR)>70)/len(accByLR)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjzQjpc5VeGVRp+BqWYPxX",
   "collapsed_sections": [],
   "name": "DUDL_ANN_multilayer.ipynb",
   "provenance": [
    {
     "file_id": "1jeqKEJfI18GlAhSG8RO5aJ6Vrp4-nkTt",
     "timestamp": 1615909315432
    },
    {
     "file_id": "10_geQnah5AvMsm8VDAQwNPhypOXradar",
     "timestamp": 1615893340208
    },
    {
     "file_id": "1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD",
     "timestamp": 1615877547147
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
