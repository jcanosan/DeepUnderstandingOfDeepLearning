{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: ANNs\n",
    "### LECTURE: Model depth vs. breadth\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3870,
     "status": "ok",
     "timestamp": 1676840552227,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     },
     "user_tz": -540
    },
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ViJutqaaNb2"
   },
   "source": [
    "# Import and organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4553,
     "status": "ok",
     "timestamp": 1676840556775,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     },
     "user_tz": -540
    },
    "id": "MU7rvmWuhjud"
   },
   "outputs": [],
   "source": [
    "MNIST = torchvision.datasets.MNIST(\".\", download=True)\n",
    "data = MNIST.data\n",
    "labels = MNIST.targets\n",
    "\n",
    "# Randomly drop samples to shrink the size to 20,000\n",
    "np.random.seed(42)  # Set random seed for reproducibility\n",
    "indices = np.random.choice(len(data), size=20000, replace=False)\n",
    "data = data[:20000]\n",
    "labels = labels[:20000]\n",
    "\n",
    "# Reshape data to 2D array\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "# Reshape labels to 2D array\n",
    "labels = labels.reshape(labels.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data / torch.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "dataT = data_norm.clone().detach().float()\n",
    "labelsT = labels.clone().detach().long()  # long = int64\n",
    "\n",
    "# Extract indexes with number 7 \n",
    "indices_7 = (labels == 7).nonzero(as_tuple=True)[0]\n",
    "indices_not_7 = (labels != 7).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Extract indexes as test data, and the opposite as train data\n",
    "train_data = dataT.index_select(dim=0, index=indices_not_7)\n",
    "train_labels = labelsT.index_select(dim=0, index=indices_not_7)\n",
    "test_data = dataT.index_select(dim=0, index=indices_7)\n",
    "test_labels = labelsT.index_select(dim=0, index=indices_7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batchsize = 32\n",
    "train_loader_norm = DataLoader(train_data,\n",
    "                               batch_size=batchsize,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True)\n",
    "test_loader_norm = DataLoader(test_data,\n",
    "                              batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCuMSE6baRar"
   },
   "source": [
    "# Construct and sanity-check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1676840556776,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     },
     "user_tz": -540
    },
    "id": "eZMzMLxfULjf"
   },
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet(optimizer_name, learning_rate, num_hidden_layers,\n",
    "                      num_hidden_units):\n",
    "\n",
    "    class mnistNet(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            ### input layer\n",
    "            self.input = nn.Linear(784, num_hidden_units)\n",
    "\n",
    "            ### hidden layer\n",
    "            self.fc_layers = [\n",
    "                nn.Linear(num_hidden_units, num_hidden_units)\n",
    "                for i in range(0, num_hidden_layers)\n",
    "            ]\n",
    "\n",
    "            ### output layer\n",
    "            self.output = nn.Linear(num_hidden_units, 10)\n",
    "\n",
    "        # forward pass\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.input(x))\n",
    "            for hidden_layer in self.fc_layers:\n",
    "                x = F.relu(hidden_layer(x))\n",
    "            return self.output(x)\n",
    "\n",
    "    # create the model instance\n",
    "    net = mnistNet()\n",
    "\n",
    "    # loss function\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer\n",
    "    optimizer_function = getattr(torch.optim, optimizer_name)\n",
    "    optimizer = optimizer_function(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    return net, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with optimizer type as input\n",
    "# SGD, RMSprop, Adam\n",
    "optim = createTheMNISTNet(optimizer_name=\"RMSprop\",\n",
    "                          learning_rate=.01,\n",
    "                          num_hidden_layers=2,\n",
    "                          num_hidden_units=50)[2]\n",
    "optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL7cvyjUaXjc"
   },
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1676840557651,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     },
     "user_tz": -540
    },
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "\n",
    "def function2trainTheModel(train_loader,\n",
    "                           test_loader,\n",
    "                           numepochs,\n",
    "                           optimizer_name,\n",
    "                           learning_rate,\n",
    "                           num_hidden_layers=2,\n",
    "                           num_hidden_units=50):\n",
    "\n",
    "    # create a new model\n",
    "    net, lossfun, optimizer = createTheMNISTNet(optimizer_name, learning_rate,\n",
    "                                                num_hidden_layers,\n",
    "                                                num_hidden_units)\n",
    "\n",
    "    # initialize losses\n",
    "    losses = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epochi in range(numepochs):\n",
    "\n",
    "        # loop over training data batches\n",
    "        batchAcc = []\n",
    "        batchLoss = []\n",
    "        for X, y in train_loader:\n",
    "            y = torch.flatten(y)\n",
    "\n",
    "            # forward pass and loss\n",
    "            yHat = net(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # compute accuracy\n",
    "            matches = torch.argmax(yHat, axis=1) == y  # booleans (false/true)\n",
    "            matchesNumeric = matches.float()  # convert to numbers (0/1)\n",
    "            accuracyPct = 100 * torch.mean(matchesNumeric)  # average and x100\n",
    "            batchAcc.append(accuracyPct)  # add to list of accuracies\n",
    "        # end of batch loop...\n",
    "\n",
    "        # now that we've trained through the batches, get their average training accuracy\n",
    "        trainAcc.append(np.mean(batchAcc))\n",
    "\n",
    "        # and get average losses across the batches\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "        # test accuracy\n",
    "        X, y = next(iter(test_loader))  # extract X,y from test dataloader\n",
    "        with torch.no_grad():\n",
    "            y = torch.flatten(y)\n",
    "            yHat = net(X)\n",
    "\n",
    "        # compare the following really long line of code to the training accuracy lines\n",
    "        testAcc.append(100 * torch.mean(\n",
    "            (torch.argmax(yHat, axis=1) == y).float()))\n",
    "\n",
    "    # end epochs\n",
    "\n",
    "    # function output\n",
    "    return trainAcc, testAcc, losses, net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "numepochs = 100\n",
    "optimizer = \"Adam\"\n",
    "learning_rate = .01\n",
    "\n",
    "print(f\"Training with {optimizer} and learning rate {learning_rate}\")\n",
    "train_accuracy_experiment, test_accuracy_experiment, losses_experiment, net_experiment = function2trainTheModel(\n",
    "    train_loader_norm,\n",
    "    test_loader_norm,\n",
    "    numepochs,\n",
    "    optimizer,\n",
    "    learning_rate,\n",
    "    num_hidden_layers=2,\n",
    "    num_hidden_units=50)\n",
    "accuracy_experiments = {\n",
    "    \"train_accuracy_experiment\": train_accuracy_experiment,\n",
    "    \"test_accuracy_experiment\": test_accuracy_experiment\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(test_loader_norm))[0]\n",
    "predictions = net_experiment(X).detach()\n",
    "guesses = torch.argmax(predictions, axis=1).detach()\n",
    "guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax[0].plot(accuracy_experiments[\"train_accuracy_experiment\"], label='Train')\n",
    "ax[0].plot(accuracy_experiments[\"test_accuracy_experiment\"], label='Test')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Accuracy (%)')\n",
    "ax[0].set_ylim([0, 100])\n",
    "ax[0].set_title('Train & Test accuracies')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(guesses, label='Test results')\n",
    "ax[1].set_xlabel('Value')\n",
    "ax[1].set_ylabel('Occurrences')\n",
    "ax[1].set_ylim([0, 15])\n",
    "ax[1].set_title('Train')\n",
    "# ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN4056RCJOTpz/xZ+H60BLF",
   "provenance": [
    {
     "file_id": "1V0mkFVCMTAd0iq30FIpXspezzE7PpVrX",
     "timestamp": 1616523401452
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1615925514977
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
