{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(low=-10, high=11, size=(3000, 2))\n",
    "sum_results = data.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "data_tensor = torch.tensor(data).float()\n",
    "results_tensor = torch.tensor(sum_results).float()\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data, train_results, test_results = train_test_split(\n",
    "    data_tensor, results_tensor, test_size=.1)\n",
    "\n",
    "# Convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data, train_results)\n",
    "test_data = torch.utils.data.TensorDataset(test_data, test_results)\n",
    "\n",
    "# Translate into dataloader objects\n",
    "batchsize = 1\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batchsize,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_tensor)\n",
    "print(data_tensor.shape)\n",
    "print(results_tensor)\n",
    "print(results_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(2, 16)\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "        self.output = nn.Linear(1, 1)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.input(x))\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNPipeline():\n",
    "\n",
    "    def __init__(self, train_loader, test_loader):\n",
    "        self._net = Net()\n",
    "        self._lossfun = nn.MSELoss()\n",
    "        self._optimizer = torch.optim.Adam(self._net.parameters(), lr=.01)\n",
    "        self._train_loader = train_loader\n",
    "        self._test_loader = test_loader\n",
    "\n",
    "    def train(self, num_epochs=100):\n",
    "        losses = torch.zeros(num_epochs)\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for epochi in range(num_epochs):\n",
    "            batch_loss = []\n",
    "            for X, y in self._train_loader:\n",
    "                # forward pass and loss\n",
    "                y_hat = self._net(X)\n",
    "                loss = self._lossfun(y_hat, y)\n",
    "\n",
    "                # backprop\n",
    "                self._optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "                # loss from this batch\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            # and get average losses across the batches\n",
    "            losses[epochi] = np.mean(batch_loss)\n",
    "\n",
    "            # compute train accuracy\n",
    "            X, y = next(iter(self._train_loader))\n",
    "            with torch.no_grad():\n",
    "                y_hat = self._net(X)\n",
    "            train_accuracy.append(100 * torch.mean(\n",
    "                (torch.abs(y_hat - train_results) < 1).float()))\n",
    "\n",
    "            # compute test accuracy\n",
    "            X, y = next(iter(self._test_loader))\n",
    "            with torch.no_grad():\n",
    "                y_hat = self._net(X)\n",
    "            test_accuracy.append(100 * torch.mean(\n",
    "                (torch.abs(y_hat - test_results) < 1).float()))\n",
    "\n",
    "        return train_accuracy, test_accuracy, losses, self._net\n",
    "\n",
    "    def predict(self, loader):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self._net(loader.dataset.tensors[0])\n",
    "        return torch.round(y_hat.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural_network_dev = NNPipeline(train_loader, test_loader)\n",
    "train_accuracy_dev, test_accuracy_dev, losses_dev, net_dev = neural_network_dev.train(num_epochs=10)\n",
    "print(f'Final training accuracy: {train_accuracy_dev}')\n",
    "print(f'Final testing accuracy: {test_accuracy_dev}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural_network_dev.predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = []\n",
    "for trained_model_index in range(10):\n",
    "    print(f\"Training model {trained_model_index}\")\n",
    "    pipeline = NNPipeline(train_loader, test_loader)\n",
    "    train_accuracy, test_accuracy, losses, net = pipeline.train(\n",
    "        num_epochs=10)\n",
    "    trained_models.append({\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"losses\": losses,\n",
    "        \"net\": net,\n",
    "        \"pipeline\": pipeline\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in trained_models:\n",
    "    print(model[\"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trained_models[-1][\"pipeline\"].predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.plot(test_loader.dataset.tensors[1], 's')\n",
    "plt.plot(test_predictions, 'rx')\n",
    "plt.legend(['True sum','Predicted sum'])\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Sum')\n",
    "plt.title('Predicted vs. actual sum')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
