{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = fetch_ucirepo(id=45)\n",
    "heart_disease.data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = heart_disease.data.features\n",
    "diagnoses = heart_disease.data.targets\n",
    "\n",
    "# data contain some NaN, so we drop those rows\n",
    "rows_with_nan = data[data.isin([np.nan]).any(axis=1)].index\n",
    "data = data.drop(rows_with_nan)\n",
    "diagnoses = diagnoses.drop(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score the non-categorical columns\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop(['sex', 'fbs', 'exang'])\n",
    "\n",
    "for c in cols2zscore:\n",
    "    d = pd.to_numeric(\n",
    "        data[c])  # force to numeric (addresses some data-format issues)\n",
    "    data[c] = (d - d.mean()) / d.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tensor and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data.values).float()\n",
    "diagnoses = torch.tensor(diagnoses.values).float()\n",
    "diagnoses = torch.where(diagnoses > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diagnoses.shape)\n",
    "print(diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "train_data, test_data, train_diagnoses, test_diagnoses = train_test_split(\n",
    "    data, diagnoses, test_size=.1)\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data, train_diagnoses)\n",
    "test_data = torch.utils.data.TensorDataset(test_data, test_diagnoses)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(13, 32)\n",
    "        self.fc1 = nn.Linear(32, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.input(x))\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNPipeline():\n",
    "\n",
    "    def __init__(self, train_loader, test_loader):\n",
    "        self._net = Net()\n",
    "        self._lossfun = nn.BCEWithLogitsLoss()\n",
    "        self._optimizer = torch.optim.Adam(self._net.parameters(), lr=.0001)\n",
    "        self._train_loader = train_loader\n",
    "        self._test_loader = test_loader\n",
    "\n",
    "    def train(self, num_epochs=100):\n",
    "        losses = torch.zeros(num_epochs)\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for epochi in range(num_epochs):\n",
    "            batch_accuracy = []\n",
    "            batch_loss = []\n",
    "            for X, y in self._train_loader:\n",
    "                # forward pass and loss\n",
    "                y_hat = self._net(X)\n",
    "                loss = self._lossfun(y_hat, y)\n",
    "\n",
    "                # backprop\n",
    "                self._optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "                # loss and accuracy for this batch\n",
    "                batch_loss.append(loss.item())\n",
    "                batch_accuracy.append(100 * torch.mean(\n",
    "                    ((y_hat > 0) == y).float()).item())\n",
    "\n",
    "            # average losses and accuracy across the batches\n",
    "            losses[epochi] = np.mean(batch_loss)\n",
    "            train_accuracy.append(np.mean(batch_accuracy))\n",
    "\n",
    "            # compute test accuracy\n",
    "            X, y = next(iter(self._test_loader))\n",
    "            with torch.no_grad():\n",
    "                y_hat = self._net(X)\n",
    "            test_accuracy.append(100 * torch.mean(\n",
    "                ((y_hat > 0) == y).float()).item())\n",
    "\n",
    "        return train_accuracy, test_accuracy, losses, self._net\n",
    "\n",
    "    def predict(self, loader):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self._net(loader.dataset.tensors[0])\n",
    "        return torch.round(y_hat.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = NNPipeline(train_loader, test_loader)\n",
    "train_accuracy, test_accuracy, losses, net = neural_network.train(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Losses: {losses}')\n",
    "print(f'Training accuracy: {train_accuracy}')\n",
    "print(f'Testing accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_title('Losses')\n",
    "ax[0].legend(\"Losses\")\n",
    "\n",
    "ax[1].plot(train_accuracy)\n",
    "ax[1].plot(test_accuracy)\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].legend([\"Train\", \"Test\"])\n",
    "ax[1].set_ylim([0, 100])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
